{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36afb123",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n"
     ]
    }
   ],
   "source": [
    "import win32com.client as win32\n",
    "import pyspark.pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.pivot.fields import Missing\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dcd971c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conversão do arquivo xls para xlsx\n",
    "\n",
    "absPath = os.path.abspath('datalake/vendas-combustiveis-m3.xls')\n",
    "excel = win32.gencache.EnsureDispatch('Excel.Application')\n",
    "wb = excel.Workbooks.Open(absPath)\n",
    "\n",
    "wb.SaveAs(absPath+'x', FileFormat = 51)\n",
    "wb.Close()                         \n",
    "excel.Application.Quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be2acc02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Função para extração da Pivot cached table\n",
    "\n",
    "def extract_pivot_cached(pivot_name, report_name):\n",
    "\n",
    "    pivot_table = [p for p in worksheet._pivots if p.name == pivot_name][0]\n",
    "\n",
    "    fields_map = {}\n",
    "    for field in pivot_table.cache.cacheFields:\n",
    "        if field.sharedItems.count > 0:\n",
    "            fields_map[field.name] = [f.v for f in field.sharedItems._fields]\n",
    "\n",
    "    column_names = [field.name for field in pivot_table.cache.cacheFields]\n",
    "    rows = []\n",
    "    for record in pivot_table.cache.records.r:\n",
    "        record_values = [\n",
    "            field.v if not isinstance(field, Missing) else np.nan for field in record._fields\n",
    "        ]\n",
    "\n",
    "        row_dict = {k: v for k, v in zip(column_names, record_values)}\n",
    "\n",
    "        for key in fields_map:\n",
    "            row_dict[key] = fields_map[key][row_dict[key]]\n",
    "\n",
    "        rows.append(row_dict)\n",
    "\n",
    "    df_pivot = pd.DataFrame.from_dict(rows)\n",
    "    df_pivot.to_parquet('datalake/bronze/'+report_name)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "355a878a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Spark\\spark-3.3.0-bin-hadoop2\\python\\pyspark\\pandas\\utils.py:975: PandasAPIOnSparkAdviceWarning: If `index_col` is not specified for `to_parquet`, the existing index is lost when converting to Parquet.\n",
      "  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n",
      "C:\\Spark\\spark-3.3.0-bin-hadoop2\\python\\pyspark\\pandas\\utils.py:975: PandasAPIOnSparkAdviceWarning: If `index_col` is not specified for `to_spark`, the existing index is lost when converting to Spark DataFrame.\n",
      "  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n",
      "C:\\Spark\\spark-3.3.0-bin-hadoop2\\python\\pyspark\\pandas\\utils.py:975: PandasAPIOnSparkAdviceWarning: If `index_col` is not specified for `to_parquet`, the existing index is lost when converting to Parquet.\n",
      "  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n",
      "C:\\Spark\\spark-3.3.0-bin-hadoop2\\python\\pyspark\\pandas\\utils.py:975: PandasAPIOnSparkAdviceWarning: If `index_col` is not specified for `to_spark`, the existing index is lost when converting to Spark DataFrame.\n",
      "  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Leitura do arquivo e extração das pivot cached tables\n",
    "workbook = load_workbook('datalake/vendas-combustiveis-m3.xlsx')\n",
    "worksheet = workbook['Plan1']\n",
    "\n",
    "report_name = 'oil'\n",
    "pivot_name ='Tabela dinâmica1'\n",
    "extract_pivot_cached(pivot_name, report_name)\n",
    "\n",
    "report_name = 'diesel'\n",
    "pivot_name ='Tabela dinâmica3'\n",
    "extract_pivot_cached(pivot_name, report_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a812c018",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
